#!/usr/bin/python
#
#  Copyright 2002-2023 Barcelona Supercomputing Center (www.bsc.es)
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#
import typing
import time
import socket

from urllib.parse import urlsplit


def process_accessed_files(dp_log: str) -> typing.Tuple[list, list]:
    """
    Process all the files the COMPSs workflow has accessed. They will be the overall inputs needed and outputs
    generated of the whole workflow.
    - If a task that is an INPUT, was previously an OUTPUT, it means it is an intermediate file, therefore we discard it
    - Works fine with COLLECTION_FILE_IN, COLLECTION_FILE_OUT and COLLECTION_FILE_INOUT

    :param dp_log: Full path to the dataprovenance.log file

    :returns: List of Inputs and Outputs of the COMPSs workflow
    """

    part_time = time.time()

    inputs = set()
    outputs = set()

    with open(dp_log, "r", encoding="UTF-8") as dp_file:
        for line in dp_file:
            file_record = line.rstrip().split(" ")
            if len(file_record) == 2:
                if (
                    file_record[1] == "IN" or file_record[1] == "IN_DELETE"
                ):  # Can we have an IN_DELETE that was not previously an OUTPUT?
                    if (
                        file_record[0] not in outputs
                    ):  # A true INPUT, not an intermediate file
                        inputs.add(file_record[0])
                    #  Else, it is an intermediate file, not a true INPUT or OUTPUT. Not adding it as an input may
                    # be enough in most cases, since removing it as an output may be a bit radical
                    #     outputs.remove(file_record[0])
                elif file_record[1] == "OUT":
                    outputs.add(file_record[0])
                else:  # INOUT, COMMUTATIVE, CONCURRENT
                    if (
                        file_record[0] not in outputs
                    ):  # Not previously generated by another task (even a task using that same file), a true INPUT
                        inputs.add(file_record[0])
                    # else, we can't know for sure if it is an intermediate file, previous call using the INOUT may
                    # have inserted it at outputs, thus don't remove it from outputs
                    outputs.add(file_record[0])
            # else dismiss the line

    l_ins = list(inputs)
    l_ins.sort()  # Put directories first
    l_outs = list(outputs)
    l_outs.sort()  # Put directories first

    # Fix dir:// references, they don't end with slash '/' at dataprovenance.log
    for data_list in [l_ins, l_outs]:
        for item in data_list:
            url_parts = urlsplit(item)
            if url_parts.scheme == "dir":
                data_list.append("dir://" + socket.gethostname() + url_parts.path + "/")
                data_list.remove(item)
            else:
                break  # File has been reached, all directories have been treated
        data_list.sort()

    print(f"PROVENANCE | COMPSs runtime detected inputs ({len(l_ins)})")
    print(f"PROVENANCE | COMPSs runtime detected outputs ({len(l_outs)})")
    print(
        f"PROVENANCE | dataprovenance.log processing TIME: "
        f"{time.time() - part_time} s"
    )

    return l_ins, l_outs
